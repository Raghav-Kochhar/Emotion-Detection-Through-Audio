{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "\n",
    "# Importing data and preprocessing\n",
    "ref = pd.read_csv(\"Data_path.csv\")\n",
    "\n",
    "# Extracting features using MFCC\n",
    "df = pd.DataFrame(columns=[\"feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each audio file\n",
    "for index, path in enumerate(ref.path):\n",
    "    X, sample_rate = librosa.load(\n",
    "        path, res_type=\"kaiser_fast\", duration=2.5, sr=44100, offset=0.5\n",
    "    )\n",
    "    # Extract MFCC features\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "    df.loc[index] = [mfccs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate extracted features with metadata\n",
    "df = pd.concat([ref, pd.DataFrame(df[\"feature\"].values.tolist())], axis=1)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"path\", \"labels\", \"source\"], axis=1).values\n",
    "y = df.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data for Conv1D\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "num_classes = len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghav/miniconda3/envs/task1/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv1D(256, 8, padding=\"same\", input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(128, 8, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(128, 8, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(128, 8, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(64, 8, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(64, 8, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720461955.967047   16076 service.cc:145] XLA service 0x7f53900199c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720461955.967101   16076 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-07-08 18:05:56.040118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-08 18:05:56.370572: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 23/286\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1620 - loss: 2.6826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720461961.900716   16076 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.2131 - loss: 2.2959 - val_accuracy: 0.0839 - val_loss: 3.4025 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2931 - loss: 1.9765 - val_accuracy: 0.3065 - val_loss: 1.9963 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3339 - loss: 1.8707 - val_accuracy: 0.3397 - val_loss: 1.8719 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3529 - loss: 1.8026 - val_accuracy: 0.3680 - val_loss: 1.8131 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3738 - loss: 1.7694 - val_accuracy: 0.3910 - val_loss: 1.7069 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3862 - loss: 1.7326 - val_accuracy: 0.3545 - val_loss: 1.8188 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4132 - loss: 1.6694 - val_accuracy: 0.3963 - val_loss: 1.6963 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3997 - loss: 1.7223 - val_accuracy: 0.3867 - val_loss: 1.7364 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4016 - loss: 1.6774 - val_accuracy: 0.3959 - val_loss: 1.6611 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4197 - loss: 1.6337 - val_accuracy: 0.4127 - val_loss: 1.6249 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4338 - loss: 1.5858 - val_accuracy: 0.3884 - val_loss: 1.7232 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4351 - loss: 1.6113 - val_accuracy: 0.4258 - val_loss: 1.5942 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4404 - loss: 1.5783 - val_accuracy: 0.3864 - val_loss: 1.7378 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4614 - loss: 1.5445 - val_accuracy: 0.4298 - val_loss: 1.6257 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4299 - loss: 1.6019 - val_accuracy: 0.4193 - val_loss: 1.6333 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4765 - loss: 1.4905 - val_accuracy: 0.4413 - val_loss: 1.5465 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4913 - loss: 1.4663 - val_accuracy: 0.4482 - val_loss: 1.5407 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4894 - loss: 1.4321 - val_accuracy: 0.4541 - val_loss: 1.5303 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 1.4080 - val_accuracy: 0.4568 - val_loss: 1.5245 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4952 - loss: 1.4204 - val_accuracy: 0.4469 - val_loss: 1.5453 - learning_rate: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4901 - loss: 1.4136 - val_accuracy: 0.4482 - val_loss: 1.5262 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5122 - loss: 1.3798 - val_accuracy: 0.4522 - val_loss: 1.5382 - learning_rate: 2.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5103 - loss: 1.3878 - val_accuracy: 0.4561 - val_loss: 1.5158 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 1.3579 - val_accuracy: 0.4558 - val_loss: 1.5129 - learning_rate: 4.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5277 - loss: 1.3541 - val_accuracy: 0.4548 - val_loss: 1.5176 - learning_rate: 4.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5203 - loss: 1.3602 - val_accuracy: 0.4577 - val_loss: 1.5131 - learning_rate: 4.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5172 - loss: 1.3634 - val_accuracy: 0.4548 - val_loss: 1.5166 - learning_rate: 4.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 1.3521 - val_accuracy: 0.4561 - val_loss: 1.5158 - learning_rate: 8.0000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5207 - loss: 1.3621 - val_accuracy: 0.4577 - val_loss: 1.5144 - learning_rate: 8.0000e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5268 - loss: 1.3460 - val_accuracy: 0.4574 - val_loss: 1.5140 - learning_rate: 8.0000e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5215 - loss: 1.3642 - val_accuracy: 0.4554 - val_loss: 1.5164 - learning_rate: 1.6000e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5391 - loss: 1.3314 - val_accuracy: 0.4577 - val_loss: 1.5154 - learning_rate: 1.6000e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5177 - loss: 1.3492 - val_accuracy: 0.4571 - val_loss: 1.5146 - learning_rate: 1.6000e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5237 - loss: 1.3380 - val_accuracy: 0.4574 - val_loss: 1.5157 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4557711184024811\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'emotion_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save(\"emotion_model.h5\")\n",
    "print(\"Model saved as 'emotion_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
